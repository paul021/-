{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务 5.2 清洗数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 检测与处理重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = './image/5-2-1.png',width=700,height=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = './image/5-2-1.png',width=700,height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-9 利用list去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前菜品总数为： 10037\n",
      "方法一去重后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-9\n",
    "import pandas as pd\n",
    "detail = pd.read_csv('../data/detail.csv',\n",
    "    index_col=0,encoding = 'gbk')\n",
    "\n",
    "##方法一\n",
    "##定义去重函数\n",
    "def delRep(list1):\n",
    "    list2=[]\n",
    "    for i in list1:\n",
    "        if i not in list2:\n",
    "            list2.append(i)\n",
    "    return list2 \n",
    "## 去重\n",
    "dishes=list(detail['dishes_name']) ##将dishes_name从数据框中提取出来\n",
    "print('去重前菜品总数为：',len(dishes)) \n",
    "dish = delRep(dishes) ##使用自定义的去重函数去重\n",
    "print('方法一去重后菜品总数为：',len(dish))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-10 利用set的特性去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前菜品总数为： 10037\n",
      "方法二去重后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "##方法二\n",
    "print('去重前菜品总数为：',len(dishes)) \n",
    "dish_set = set(dishes) ##利用set的特性去重\n",
    "print('方法二去重后菜品总数为：',len(dish_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = './image/5-2-2.png',width=700,height=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = './image/5-2-2.png',width=700,height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-11 使用drop_duplicates方法对菜品名称去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前菜品总数为： 10037\n",
      "方法二去重后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "##方法二\n",
    "print('去重前菜品总数为：',len(dishes)) \n",
    "dish_set = set(dishes) ##利用set的特性去重\n",
    "print('方法二去重后菜品总数为：',len(dish_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-12 使用drop_duplicates方法对多列去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重之前订单详情表的形状为： (10037, 18)\n",
      "依照订单编号，会员编号去重之后订单详情表大小为: (942, 18)\n"
     ]
    }
   ],
   "source": [
    "print('去重之前订单详情表的形状为：', detail.shape)\n",
    "shapeDet = detail.drop_duplicates(subset = ['order_id','emp_id']).shape\n",
    "print('依照订单编号，会员编号去重之后订单详情表大小为:', shapeDet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = './image/5-2-3.png',width=700,height=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = './image/5-2-3.png',width=700,height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-13 求出counts和amounts两列数据的kendall法相似度矩阵\n",
    "https://blog.csdn.net/zhaozhn5/article/details/78392220\n",
    "但是通过相似度矩阵去重存在一个弊端，该方法只能对数值型重复特征去重，类别型特征之间无法通过计算相似系数来衡量相似度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销量和售价的kendall相似度为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.229968\n",
      "amounts -0.229968  1.000000\n"
     ]
    }
   ],
   "source": [
    "## 求取销量和售价的相似度\n",
    "corrDet = detail[['counts','amounts']].corr(method='kendall')\n",
    "print('销量和售价的kendall相似度为：\\n',corrDet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-14 求出dishes_name,counts和amounts这3个特征的pearson法相似度矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜品名称，销量和售价的pearson相似度为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.159264\n",
      "amounts -0.159264  1.000000\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-14\n",
    "corrDet1 = detail[['dishes_name','counts',\n",
    "    'amounts']].corr(method='pearson')\n",
    "print('菜品名称，销量和售价的pearson相似度为：\\n',corrDet1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了使用相似度矩阵进行特征去重之外，可以通过DataFrame.equals的方法进行特征去重。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-15 使用DataFrame.equals方法去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail的特征相等矩阵的前5行5列为：\n",
      "                   order_id dishes_id logicprn_name parent_class_name  \\\n",
      "order_id              True     False         False             False   \n",
      "dishes_id            False      True         False             False   \n",
      "logicprn_name        False     False          True              True   \n",
      "parent_class_name    False     False          True              True   \n",
      "dishes_name          False     False         False             False   \n",
      "\n",
      "                  dishes_name  \n",
      "order_id                False  \n",
      "dishes_id               False  \n",
      "logicprn_name           False  \n",
      "parent_class_name       False  \n",
      "dishes_name              True  \n"
     ]
    }
   ],
   "source": [
    "##定义求取特征是否完全相同的矩阵的函数\n",
    "def FeatureEquals(df):\n",
    "    dfEquals=pd.DataFrame([],columns=df.columns,index=df.columns)\n",
    "    for i in df.columns:\n",
    "       for j in df.columns:\n",
    "           dfEquals.loc[i,j]=df.loc[:,i].equals(df.loc[:,j])\n",
    "    return dfEquals\n",
    "## 应用上述函数\n",
    "detEquals=FeatureEquals(detail)\n",
    "print('detail的特征相等矩阵的前5行5列为：\\n',detEquals.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-16 通过遍历的方式进行数据筛选\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要删除的列为： ['parent_class_name', 'cost', 'discount_amt', 'discount_reason', 'kick_back', 'add_info', 'bar_code', 'add_inprice']\n",
      "删除多余列后detail的特征数目为： 10\n"
     ]
    }
   ],
   "source": [
    "##遍历所有数据\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k+1,lenDet):\n",
    "        if detEquals.iloc[k,l] & (detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "##进行去重操作\n",
    "print('需要删除的列为：',dupCol)\n",
    "detail.drop(dupCol,axis=1,inplace=True)\n",
    "print('删除多余列后detail的特征数目为：',detail.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2 检测与处理缺失值\n",
    "数据中的某个或某些特征的值是不完整的，这些值称为缺失值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-17 isnull和notnull用法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail每个特征缺失的数目为：\n",
      " order_id                0\n",
      "dishes_id               0\n",
      "logicprn_name       10037\n",
      "dishes_name             0\n",
      "itemis_add              0\n",
      "counts                  0\n",
      "amounts                 0\n",
      "place_order_time        0\n",
      "picture_file            0\n",
      "emp_id                  0\n",
      "dtype: int64\n",
      "detail每个特征非缺失的数目为：\n",
      " order_id            10037\n",
      "dishes_id           10037\n",
      "logicprn_name           0\n",
      "dishes_name         10037\n",
      "itemis_add          10037\n",
      "counts              10037\n",
      "amounts             10037\n",
      "place_order_time    10037\n",
      "picture_file        10037\n",
      "emp_id              10037\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('detail每个特征缺失的数目为：\\n',detail.isnull().sum())\n",
    "print('detail每个特征非缺失的数目为：\\n',detail.notnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结合sum函数和isnull、notnull函数，可以检测数据中缺失值的分布以及数据中一共含有多少缺失值。\n",
    "isnull和notnull之间结果正好相反，因此使用其中任意一个都可以判断出数据中缺失值的位置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = './image/5-2-4.png',width=700,height=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = './image/5-2-4.png',width=700,height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-18 使用dropna方法删除确实值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除缺失的列前detail的形状为： (10037, 10)\n",
      "去除缺失的列后detail的形状为： (10037, 9)\n"
     ]
    }
   ],
   "source": [
    "print('去除缺失的列前detail的形状为：', detail.shape)\n",
    "print('去除缺失的列后detail的形状为：',\n",
    "    detail.dropna(axis = 1,how ='any').shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-19 使用fillna方法替换缺失值\n",
    "替换法是指用一个特定的值替换缺失值。\n",
    "特征可分为数值型和类别型，两者出现缺失值时的处理方法也是不同的。\n",
    "缺失值所在特征为数值型时，通常利用其均值、中位数和众数等描述其集中趋势的统计量来代替缺失值。\n",
    "缺失值所在特征为类别型时，则选择使用众数来替换缺失值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = './image/5-2-5.png',width=700,height=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = './image/5-2-5.png',width=700,height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail每个特征缺失的数目为：\n",
      " order_id            0\n",
      "dishes_id           0\n",
      "logicprn_name       0\n",
      "dishes_name         0\n",
      "itemis_add          0\n",
      "counts              0\n",
      "amounts             0\n",
      "place_order_time    0\n",
      "picture_file        0\n",
      "emp_id              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "detail = detail.fillna(-99)\n",
    "print('detail每个特征缺失的数目为：\\n',detail.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-9 利用list去重\n",
    "#### 3. 插值法\n",
    "删除法简单易行，但是会引起数据结构变动，样本减少；替换法使用难度较低，但是会影响数据的标准差，导致信息量变动。在面对数据缺失问题时，除了这两种方法之外，还有一种常用的方法—插值法。\n",
    "常用的插值法有线性插值、多项式插值和样条插值等：\n",
    "线性插值是一种较为简单的插值方法，它针对已知的值求出线性方程，通过求解线性方程得到缺失值。\n",
    "多项式插值是利用已知的值拟合一个多项式，使得现有的数据满足这个多项式，再利用这个多项式求解缺失值，常见的多项式插值法有拉格朗日插值和牛顿插值等。\n",
    "样条插值是以可变样条来作出一条经过一系列点的光滑曲线的插值方法，插值样条由一些多项式组成，每一个多项式都是由相邻两个数据点决定，这样可以保证两个相邻多项式及其导数在连接处连续。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为6、7时，使用线性插值y1为： [ 76. 102.]\n",
      "当x为6、7时，使用线性插值y2为： [13. 15.]\n"
     ]
    }
   ],
   "source": [
    "## 线性插值\n",
    "from scipy.interpolate import interp1d\n",
    "x=np.array([1,2,3,4,5,8,9,10]) ##创建自变量x\n",
    "y1=np.array([2,8,18,32,50,128,162,200]) ##创建因变量y1\n",
    "y2=np.array([3,5,7,9,11,17,19,21]) ##创建因变量y2\n",
    "LinearInsValue1 = interp1d(x,y1,kind='linear') ##线性插值拟合x,y1\n",
    "LinearInsValue2 = interp1d(x,y2,kind='linear') ##线性插值拟合x,y2\n",
    "print('当x为6、7时，使用线性插值y1为：',LinearInsValue1([6,7]))\n",
    "print('当x为6、7时，使用线性插值y2为：',LinearInsValue2([6,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为6,7时，使用拉格朗日插值y1为： [72. 98.]\n",
      "当x为6,7时，使用拉格朗日插值y2为： [13. 15.]\n"
     ]
    }
   ],
   "source": [
    "## 拉格朗日插值\n",
    "from scipy.interpolate import lagrange\n",
    "LargeInsValue1 = lagrange(x,y1) ##拉格朗日插值拟合x,y1\n",
    "LargeInsValue2 = lagrange(x,y2) ##拉格朗日插值拟合x,y2\n",
    "print('当x为6,7时，使用拉格朗日插值y1为：',LargeInsValue1([6,7]))\n",
    "print('当x为6,7时，使用拉格朗日插值y2为：',LargeInsValue2([6,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为6,7时，使用样条插值y1为： [ 76. 102.]\n",
      "当x为6,7时，使用样条插值y2为： [13. 15.]\n"
     ]
    }
   ],
   "source": [
    "##样条插值\n",
    "import scipy.interpolate as spi\n",
    "##样条插值拟合x,y1\n",
    "ipo1 = spi.splrep(x,y1,k=1)  #样本点导入，生成参数\n",
    "SplineInsValue1 = spi.splev([6,7],ipo1)\n",
    "##样条插值拟合x,y2\n",
    "ipo2 = spi.splrep(x,y2,k=1)  #样本点导入，生成参数\n",
    "SplineInsValue2 = spi.splev([6,7],ipo2)\n",
    "print('当x为6,7时，使用样条插值y1为：',SplineInsValue1)\n",
    "print('当x为6,7时，使用样条插值y2为：',SplineInsValue2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从拟合结果可以看出多项式插值和样条插值在两种情况下拟合都非常出色，线性插值法只在自变量和因变量为线性关系的情况下拟合才较为出色。\n",
    "而在实际分析过程中，自变量与因变量的关系是线性的情况非常少见，所以在大多数情况下，多项式插值和样条插值是较为合适的选择。\n",
    "SciPy库中的interpolate模块除了提供常规的插值法外，还提供了例如在图形学领域具有重要作用的重心坐标插值（BarycentricInterpolator）等。在实际应用中，需要根据不同的场景，选择合适的插值方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.3 检测与处理异常值\n",
    "异常值是指数据中个别值的数值明显偏离其余的数值，有时也称为离群点，检测异常值就是检验数据中是否有录入错误以及是否含有不合理的数据。\n",
    "异常值的存在对数据分析十分危险，如果计算分析过程的数据有异常值，那么会对结果会产生不良影响，从而导致分析结果产生偏差乃至错误。\n",
    "常用的异常值检测主要为3σ原则和箱线图分析两种方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = './image/5-3-1.png',width=700,height=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = './image/5-3-1.png',width=700,height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-21 使用3σ原则识别异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用拉依达准则判定异常值个数为: 209\n",
      "异常值的最大值为： 10\n",
      "异常值的最小值为： 3\n"
     ]
    }
   ],
   "source": [
    "## 定义3σ拉依达准则识别异常值函数\n",
    "def outRange(Ser1):\n",
    "    boolInd = (Ser1.mean()-3*Ser1.std()>Ser1) | \\\n",
    "    (Ser1.mean()+3*Ser1.var()< Ser1)\n",
    "    index = np.arange(Ser1.shape[0])[boolInd]\n",
    "    outrange = Ser1.iloc[index]\n",
    "    return outrange\n",
    "outlier = outRange(detail['counts'])\n",
    "print('使用拉依达准则判定异常值个数为:',outlier.shape[0])\n",
    "print('异常值的最大值为：',outlier.max())\n",
    "print('异常值的最小值为：',outlier.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-22 菜品售价根据箱线图识别异常值\n",
    "#### 2.箱线图分析\n",
    "箱型图提供了识别异常值的一个标准，即异常值通常被定义为小于QL-1.5IQR或大于QU+1.5IQR的值。\n",
    "QL称为下四分位数，表示全部观察值中有四分之一的数据取值比它小。\n",
    "QU称为上四分位数，表示全部观察值中有四分之一的数据取值比它大。\n",
    "IQR称为四分位数间距，是上四分位数QU与下四分位数QL之差，其间包含了全部观察值的一半。\n",
    "箱线图依据实际数据绘制，真实、直观地表现出了数据分布的本来面貌，且没有对数据做任何限制性要求，其判断异常值的标准以四分位数和四分位数间距为基础。\n",
    "四分位数给出了数据分布的中心、散布和形状的某种指示，具有一定的鲁棒性，即25%的数据可以变得任意远而不会很大地扰动四分位数，所以异常值通常不能对这个标准施加影响。鉴于此，箱线图识别异常值的结果比较客观，因此在识别异常值方面具有一定的优越性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售量数据异常值个数为： 516\n",
      "销售量数据异常值的最大值为： 10\n",
      "销售量数据异常值的最小值为： 2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8)) \n",
    "p = plt.boxplot(detail['counts'].values,notch=True)   ##画出箱线图\n",
    "outlier1 = p['fliers'][0].get_ydata()   ##fliers为异常值的标签\n",
    "plt.savefig('../tmp/菜品异常数据识别.png')\n",
    "plt.show()\n",
    "print('销售量数据异常值个数为：',len(outlier1))\n",
    "print('销售量数据异常值的最大值为：',max(outlier1))\n",
    "print('销售量数据异常值的最小值为：',min(outlier1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.4 任务实现\n",
    "### 5-23 订单详情表的样本去重去特征去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行去重操作前订单详情表的形状为： (10037, 18)\n",
      "进行去重操作后订单详情表的形状为： (10037, 10)\n"
     ]
    }
   ],
   "source": [
    "detail = pd.read_csv('../data/detail.csv',\n",
    "    index_col=0,encoding = 'gbk')\n",
    "print('进行去重操作前订单详情表的形状为：',detail.shape)\n",
    "##样本去重\n",
    "detail.drop_duplicates(inplace = True)\n",
    "##特征去重\n",
    "def FeatureEquals(df):\n",
    "    ##定义求取特征是否完全相同的矩阵的函数\n",
    "    dfEquals=pd.DataFrame([],columns=df.columns,index=df.columns)\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            dfEquals.loc[i,j]=df.loc[:,i].equals(df.loc[:,j])\n",
    "    return dfEquals\n",
    "detEquals=FeatureEquals(detail)## 应用上述函数\n",
    "##遍历所有数据\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k+1,lenDet):\n",
    "        if detEquals.iloc[k,l] & (detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "##删除重复列\n",
    "detail.drop(dupCol,axis=1,inplace=True)\n",
    "print('进行去重操作后订单详情表的形状为：',detail.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-9 订单详情表的缺失值检测与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail每个特征缺失的率为：\n",
      " order_id              0.0%\n",
      "dishes_id             0.0%\n",
      "logicprn_name       100.0%\n",
      "dishes_name           0.0%\n",
      "itemis_add            0.0%\n",
      "counts                0.0%\n",
      "amounts               0.0%\n",
      "place_order_time      0.0%\n",
      "picture_file          0.0%\n",
      "emp_id                0.0%\n",
      "dtype: object\n",
      "经过缺失值处理后订单详情表各特征缺失值的数目为：\n",
      " order_id            0\n",
      "dishes_id           0\n",
      "dishes_name         0\n",
      "itemis_add          0\n",
      "counts              0\n",
      "amounts             0\n",
      "place_order_time    0\n",
      "picture_file        0\n",
      "emp_id              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##统计各个特征的缺失率\n",
    "naRate = (detail.isnull().sum()/ \\\n",
    "    detail.shape[0]*100).astype('str')+'%'\n",
    "print('detail每个特征缺失的率为：\\n',naRate)\n",
    "##删除全部均为缺失的列\n",
    "detail.dropna(axis = 1,how = 'all',inplace = True)\n",
    "print('经过缺失值处理后订单详情表各特征缺失值的数目为：\\n',\n",
    "    detail.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-25 订单详情表异常值检测与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售量最小值为： 1.0\n",
      "销售量最大值为： 1.0\n",
      "售价最小值为： 1.0\n",
      "售价最大值为： 99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Study\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "def outRange(Ser1):\n",
    "    QL = Ser1.quantile(0.25)\n",
    "    QU = Ser1.quantile(0.75)\n",
    "    IQR = QU-QL\n",
    "    Ser1.loc[Ser1>(QU+1.5*IQR)] = QU\n",
    "    Ser1.loc[Ser1<(QL-1.5*IQR)] = QL\n",
    "    return Ser1\n",
    "## 处理销售量和售价的异常值\n",
    "detail['counts'] = outRange(detail['counts'])\n",
    "detail['amounts'] = outRange(detail['amounts'])\n",
    "##查看处理后的销售量和售价的最小值，最大值\n",
    "print('销售量最小值为：', detail['counts'].min())\n",
    "print('销售量最大值为：', detail['counts'].max())\n",
    "print('售价最小值为：', detail['amounts'].min())\n",
    "print('售价最大值为：', detail['amounts'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-9 利用list去重\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
